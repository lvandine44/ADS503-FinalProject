---
title: "Final Project MI"
output: html_document
date: "2024-06-17"
---

```{r}
# Import Packages 
library(dplyr)
library(tidyr)
library(ggplot2)
library(pROC)
library(caret)
library(gbm)
```

### EDA

```{r}
osteo_df <- as.data.frame(osteoporosis)
head(osteo_df)
```

```{r}
# Structure of Dataset 
str(osteo_df)
```

```{r}
# Change character variables to factors 
osteo_df <- osteo_df |>
  mutate_if(is.character, as.factor)
```

```{r}
# Change outcome variable to factor
osteo_df$Osteoporosis <- as.factor(osteo_df$Osteoporosis)
```

```{r}
# Structure of Dataset after Mutate
str(osteo_df)
```

```{r}
tail(osteo_df)
```

```{r}
# Missing Data - There is no missing data 
colSums(is.na(osteo_df))
```

```{r}
# Summary of Age Column (Integer)
summary(osteo_df$Age)
```

```{r}
ggplot(osteo_df, aes(x = Age)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Age", x = "Age", y = "Frequency") +
  theme_minimal()
```

```{r}
# Frequency for Categorical Variables (as Factors) 
df_long <- osteo_df |>
    pivot_longer(!c(Id, Age), names_to = "Variable", values_to = "Value")

# Create the plot
ggplot(df_long, aes(x = Value, fill = Variable)) + 
  geom_bar(show.legend = FALSE) + 
  facet_wrap(~ Variable, scales = "free", ncol = 4) + 
  labs(title = "Frequency of Categorical Variables", x = "Category", y = "Frequency") +
  theme_minimal()

```

```{r}
# Checking for duplicates
duplicated_rows <- duplicated(osteo_df)

# Number of duplicate rows
num_duplicates <- sum(duplicated_rows)

# Print duplicate rows
duplicate_rows <- osteo_df[duplicated_rows, ]
duplicate_rows
```

```{r}
# Check for Correlation with categorical variables and outcome variables 
cols_to_analyze <- setdiff(names(osteo_df), c("Age", "Id", "Osteoporosis"))

# Perform chi-square test for each column
results <- lapply(cols_to_analyze, function(col) {
  chisq_test <- chisq.test(table(osteo_df[[col]], osteo_df$Osteoporosis))
  return(chisq_test)
})

# Print the results
for (i in seq_along(cols_to_analyze)) {
  cat("Chi-square test for", cols_to_analyze[i], ":\n")
  print(results[[i]])
  cat("\n")
}

```

### PreProcessing

```{r}
predictors <- osteo_df[, 2:(ncol(osteo_df) - 1)]
response <- osteo_df[, ncol(osteo_df)]
```

```{r}
set.seed(503)
# Split the data into training and test sets
osteo_index <- createDataPartition(response, p = 0.8, list = FALSE)
```

```{r}

predictors_train <- predictors[osteo_index, ]
predictors_test <- predictors[-osteo_index, ]
yield_train <- response[osteo_index ]
yield_test <- response[-osteo_index ]
```

```{r}
# Change factors to numeric for LDA 
predictors_train <- data.frame(lapply(predictors_train, function(x) {
  if (is.factor(x)) as.numeric(x) else x
}))
```

```{r}
# Change factors to numeric for LDA 
predictors_test <- data.frame(lapply(predictors_test, function(x) {
  if (is.factor(x)) as.numeric(x) else x
}))
```

```{r}
# Check for missing data 
sum(is.na(predictors_train)) 
```

```{r}
# Check for missing data 
sum(is.na(predictors_test)) 
```

### Modeling

```{r}
levels(yield_train) <- make.names(levels(yield_train))
levels(yield_test) <- make.names(levels(yield_test))

ctrl <- trainControl(method = "cv", 
                    summaryFunction = twoClassSummary,
                    classProbs = TRUE,
                    savePredictions = TRUE)
```

```{r}
set.seed(503)
# Fit logistic regression model
log_model <- train(x = predictors_train,
    y = yield_train,
    method = "glm",
    preProcess = c("center", "scale"),
    metric = "ROC",
    trControl = ctrl)

# Summary of the model
summary(log_model)
```

```{r}
Log_CM <- confusionMatrix(log_model, norm = "none")
Log_CM
```

```{r}
Log_predictions <- predict(log_model, newdata = predictors_test, type = "prob")
Log_probs <- Log_predictions[, "X1"]
```

```{r}
roc_obj_log <- roc(yield_test, Log_probs)

# Plot the ROC curve
plot(roc_obj_log, main = "ROC Curve for Log Model")

# Add AUC to the plot
auc(roc_obj_log)
```

```{r}
LogImp <- varImp(log_model, scale = FALSE)
plot(LogImp)
```

```{r}
#LDA 
set.seed(503)
LDA_model <- train(x = predictors_train,
    y = yield_train,
    method = "lda",
    metric = "ROC",
    preProcess = c("center", "scale"),
    trControl = ctrl)
```

```{r}
LDA_CM <- confusionMatrix(LDA_model, norm = "none")
LDA_CM
```

```{r}
LDA_predictions <- predict(LDA_model, newdata = predictors_test, type = "prob")
LDA_probs <- LDA_predictions[, "X1"]
```

```{r}
LDA_roc_obj <- roc(yield_test, LDA_probs)

# Plot the ROC curve
plot(LDA_roc_obj, main = "ROC Curve for LDA Model")

# Add AUC to the plot
auc(LDA_roc_obj)
```

```{r}
LDAImp <- varImp(LDA_model, scale = FALSE)
plot(LDAImp)
```

```{r}
# Penalized Model 
glmnGrid <- expand.grid(alpha = c(0, .1, .2, .4, .6, .8, 1),
lambda = seq(.01, .2, length = 10))

set.seed(503)

Penalized_model <- train(x = predictors_train,
    y = yield_train,
    method = "glmnet",
    tuneGrid = glmnGrid,
    metric = "ROC",
    trControl = ctrl)
```

```{r}
Penalized_CM <- confusionMatrix(Penalized_model, norm = "none")
Penalized_CM
```

```{r}
penalized_predictions <- predict(Penalized_model, newdata = predictors_test, type = "prob")
penalized_probs <- penalized_predictions[, "X1"]
```

```{r}
penalized_roc_obj <- roc(yield_test, penalized_probs)

# Plot the ROC curve
plot(penalized_roc_obj, main = "ROC Curve for Penalized Model")

# Add AUC to the plot
auc(penalized_roc_obj)
```

```{r}
# No importance run for Penalized model; model's focus is on coefficients and their magnitudes rather than providing a ranking or importance score for each feature.
```

```{r}
# Nearest Shrunken Centroid
set.seed(503)
nsc_model <- train(x = predictors_train,
    y = yield_train,
    method = "pam",
    preProc = c("center", "scale"),
    tuneGrid = data.frame(threshold = seq(0, 25, length = 30)),
    metric = "ROC",
    trControl = ctrl)

```

```{r}
nsc_CM <- confusionMatrix(nsc_model, norm = "none")
nsc_CM
```

```{r}
nsc_predictions <- predict(nsc_model, newdata = predictors_test, type = "prob")
nsc_probs <- nsc_predictions[, "X1"]
```

```{r}
nsc_roc_obj <- roc(yield_test, nsc_probs)

# Plot the ROC curve
plot(nsc_roc_obj, main = "ROC Curve for Nsc Model")

# Add AUC to the plot
auc(nsc_roc_obj)
```

```{r}
# No importance run for NSC, has no direct measure of variable importance; model is more concerned with the classification decision boundaries than with the contribution of individual features.
```

```{r}
# Neural Net
set.seed(503)
nn_grid <- expand.grid(decay = c(0, 0.01, 0.1), size = 1:10)

neuralnet <- train(x = predictors_train,
                       y = yield_train,
                       method = "nnet",
                       tuneGrid =  nn_grid,
                       preProc = c("center", "scale"),
                       trControl = ctrl,  
                       metric = "ROC",
                       linout = FALSE, trace = FALSE, maxit = 500)
```

```{r}
neural_CM <- confusionMatrix(neuralnet, norm = "none")
neural_CM
```

```{r}
neuralnet
```

```{r}
net_predictions <- predict(neuralnet, newdata = predictors_test, type = "prob")
net_probs <- net_predictions[, "X1"]
```

```{r}
net_roc_obj <- roc(yield_test, net_probs)

# Plot the ROC curve
plot(net_roc_obj, main = "ROC Curve for Neural Net Model")

# Add AUC to the plot
auc(net_roc_obj)
```

```{r}
nnetImp <- varImp(neuralnet, scale = FALSE)
plot(nnetImp)
```

```{r}
# SVM model
svm_grid <- expand.grid(sigma = c(0.01, 0.1, 1), 
                        C = c(0.1, 1, 10))

set.seed(503)

svm <- train(x = predictors_train,
                   y = yield_train,
                   method = "svmRadial", 
                   preProc = c("center", "scale"),
                   trControl = ctrl,  
                   metric = "ROC",
                   tuneGrid = svm_grid)

```

```{r}
svm_CM <- confusionMatrix(svm, norm = "none")
svm_CM
```

```{r}
svm_predictions <- predict(svm, newdata = predictors_test, type = "prob")
svm_probs <- svm_predictions[, "X1"]
```

```{r}
svm_roc_obj <- roc(yield_test, svm_probs)

# Plot the ROC curve
plot(svm_roc_obj, main = "ROC Curve for SVM Model")

# Add AUC to the plot
auc(svm_roc_obj)
```

```{r}
svmImp <- varImp(svm, scale = FALSE)
plot(svmImp)
```

```{r}
# Mixture Discriminant Analysis

set.seed(503)

mda <- train(x = predictors_train,
               y = yield_train,
               method = "mda",
               tuneGrid = expand.grid(subclasses=1:3),
               metric = "ROC",
               trControl = ctrl)

```

```{r}
mda_CM <- confusionMatrix(mda, norm = "none")
mda_CM
```

```{r}
mda
```

```{r}
mda_predictions <- predict(mda, newdata = predictors_test, type = "prob")
mda_probs <- mda_predictions[, "X1"]
```

```{r}
mda_roc_obj <- roc(yield_test, mda_probs)

# Plot the ROC curve
plot(mda_roc_obj, main = "ROC Curve for mda Model")

# Add AUC to the plot
auc(mda_roc_obj)
```

```{r}
mdaImp <- varImp(mda, scale = FALSE)
plot(mdaImp)
```

```{r}
# Single Hidden Layer Neural Network

set.seed(503)

nnetGrid <- expand.grid(size=1:3, decay=c(0,0.1,0.2,0.3,0.4,0.5,1,2))

SHLnnet <- train(x = predictors_train,
                y = yield_train,
                method = "nnet",
                tuneGrid = nnetGrid,
                metric = "ROC",
                trace = FALSE, 
                maxit = 2000, 
                trControl = ctrl)
```

```{r}
SHLnnet_CM <- confusionMatrix(SHLnnet, norm = "none")
SHLnnet_CM
```

```{r}
SHLnnet
```

```{r}
SHLnnet_predictions <- predict(SHLnnet, newdata = predictors_test, type = "prob")
SHLnnet_probs <- SHLnnet_predictions[, "X1"]
```

```{r}
SHLnnet_roc_obj <- roc(yield_test, SHLnnet_probs)

# Plot the ROC curve
plot(SHLnnet_roc_obj, main = "ROC Curve for SLH NNet Model")

# Add AUC to the plot
auc(SHLnnet_roc_obj)
```

```{r}
SHLnnetImp <- varImp(SHLnnet, scale = FALSE)
plot(SHLnnetImp)
```

```{r}
# K-Nearest neighbors

set.seed(503)

knn <- train(x = predictors_train,
                y = yield_train,
                method = "knn",
                tuneLength = 20,
                metric = "ROC",
                trControl = ctrl)
```

```{r}
knn_CM <- confusionMatrix(knn, norm = "none")
knn_CM
```

```{r}
knn
```

```{r}
knn_predictions <- predict(knn, newdata = predictors_test, type = "prob")
knn_probs <- knn_predictions[, "X1"]
```

```{r}
knn_roc_obj <- roc(yield_test, knn_probs)

# Plot the ROC curve
plot(knn_roc_obj, main = "ROC Curve for K-NNB Model")

# Add AUC to the plot
auc(knn_roc_obj)
```

```{r}
knnImp <- varImp(knn, scale = FALSE)
plot(knnImp)
```

```{r}
# Stochiastic Gradient Boosting

gbmGrid <- expand.grid(interaction.depth = c(1, 3, 5, 7, 9),
                       n.trees = (1:20)*100,
                       shrinkage = c(.01, .1),
                       n.minobsinnode = 5)

set.seed(503)

SGboost <- train(x = predictors_train,
                y = yield_train,
                method = "gbm",
                tuneGrid = gbmGrid,
                verbose = FALSE,
                metric = "ROC",
                trControl = ctrl)
```

```{r}
SGboost_CM <- confusionMatrix(SGboost, norm = "none")
SGboost_CM
```

```{r}
SGboost
```

```{r}
SGboost_predictions <- predict(SGboost, newdata = predictors_test, type = "prob")
SGboost_probs <- SHLnnet_predictions[, "X1"]
```

```{r}
SGboost_roc_obj <- roc(yield_test, SGboost_probs)

# Plot the ROC curve
plot(SGboost_roc_obj, main = "ROC Curve for SG Boost Model")

# Add AUC to the plot
auc(SGboost_roc_obj)
```

```{r}
SGboostImp <- varImp(SGboost, scale = FALSE)
plot(SGboostImp)
```

```{r}
# random forest

set.seed(503)

mtryGrid <- data.frame(mtry = floor(seq(10, ncol(predictors_train)/3, length = 10)))

rf <- train(x = predictors_train,
                y = yield_train,
                method = "rf",
                tuneGrid = mtryGrid,
                ntree = 500,
                importance = TRUE,
                trControl = ctrl)
```

```{r}
rf_CM <- confusionMatrix(rf, norm = "none")
rf_CM
```

```{r}
rf
```

```{r}
rf_predictions <- predict(rf, newdata = predictors_test, type = "prob")
rf_probs <- rf_predictions[, "X1"]
```

```{r}
rf_roc_obj <- roc(yield_test, rf_probs)

# Plot the ROC curve
plot(rf_roc_obj, main = "ROC Curve for Random Forest Model")

# Add AUC to the plot
auc(rf_roc_obj)
```

```{r}
rfImp <- varImp(rf, scale = FALSE)
plot(rfImp)
```

```{r}
### Compare Models using ROC curve

# Set plot margins to make more space for the legend and title
par(mar = c(5, 4, 4, 8) + 0.1)

# Linear regression Models
plot(roc_obj_log, type = "s", col = 'red', legacy.axes = TRUE)
plot(LDA_roc_obj, type = "s", add = TRUE, col = 'green', legacy.axes = TRUE)
plot(penalized_roc_obj, type = "s", add = TRUE, col = 'blue', legacy.axes = TRUE)
plot(nsc_roc_obj, type = "s", add = TRUE, col = 'lightblue', legacy.axes = TRUE)
plot(svm_roc_obj, type = "s", add = TRUE, col = 'orange', legacy.axes = TRUE)

#  Non-linear regression Models
plot(net_roc_obj, type = "s", col = 'cyan', legacy.axes = TRUE)
plot(mda_roc_obj, type = "s", add = TRUE, col = 'darkblue', legacy.axes = TRUE)
plot(SHLnnet_roc_obj, type = "s", add = TRUE, col = 'violet', legacy.axes = TRUE)
plot(knn_roc_obj, type = "s", add = TRUE, col = 'darkgreen', legacy.axes = TRUE)
plot(SGboost_roc_obj, type = "s", add = TRUE, col = 'purple',legacy.axes = TRUE)
plot(rf_roc_obj, type = "s", add = TRUE, col = 'hotpink',legacy.axes = TRUE)

# Add legend with smaller font
legend("bottomright", legend = c("Logistic Regression", "Linear Discriminant Analysis",    "Penalized Regression", "Nearest Shrunken Centroid", "Neural Net", "Support Vector       Machine","Mixture Discriminant Analysis", "Single Hidden Layer Neural Net", 
    "k-Nearest Neighbor", "SG Boost", "Random Forest"),col = c("red", "green", "blue",     "lightblue", "cyan", "orange", "darkblue", "violet", "darkgreen", "purple", "hotpink"     ), lwd = 2, cex = 0.7, inset = c(0.01, 0))

# Add title with adjusted position
title(main = "Compare ROC curves from different models", line = 3)
```

```{r}
# AUC values pulled from ROC objects
Log_auc <- auc(roc_obj_log)
LDA_auc <- auc(LDA_roc_obj)
penalized_auc  <- auc(penalized_roc_obj)
nsc_auc  <- auc(nsc_roc_obj)
net_auc  <- auc(net_roc_obj) 
svm_auc  <- auc(svm_roc_obj)
mda_auc  <- auc(mda_roc_obj)
SHLnnet_auc  <- auc(SHLnnet_roc_obj)
knn_auc  <- auc(knn_roc_obj)
SGboost_auc  <- auc(SGboost_roc_obj)
rf_auc  <- auc(rf_roc_obj)

model_names = c("Logistic Regression", "Linear Discriminant Analysis", "Penalized Regression", "Nearest         Shrunken Centroid", "Neural Net", "Support Vector Machine", "Mixture Discriminant Analysis",           "Single Hidden Layer Neural Net", "k-Nearest Neighbor", "SG Boost", "Random Forest")

summary_table <- data.frame(
    Model = model_names, 
    AUC = c(Log_auc, LDA_auc, penalized_auc, nsc_auc, net_auc, svm_auc, mda_auc, SHLnnet_auc, knn_auc,           SGboost_auc, rf_auc)
)

summary_table <- summary_table |>
     arrange(desc(AUC))
print(summary_table)
```

```{r}
# Define a function to extract metrics from confusion matrices
extract_metrics <- function(conf_matrix) {
  accuracy <- conf_matrix$overall["Accuracy"]
  return(data.frame(Accuracy = accuracy))
}

# Example: Extract metrics from existing confusion matrices
log_metrics <- extract_metrics(Log_CM)
lda_metrics <- extract_metrics(LDA_CM)
penalized_metrics <- extract_metrics(Penalized_CM)
nsc_metrics <- extract_metrics(nsc_CM)
net_metrics <- extract_metrics(neural_CM)
svm_metrics <- extract_metrics(svm_CM)
mda_metrics <- extract_metrics(mda_CM)
shlnn_metrics <- extract_metrics(SHLnnet_CM)
knn_metrics <- extract_metrics(knn_CM)
sgboost_metrics <- extract_metrics(SGboost_CM)
rf_metrics <- extract_metrics(rf_CM)

# Create a summary table
accuracy_summary <- data.frame(
    Model = c("Logistic Regression", "Linear Discriminant Analysis", "Penalized Regression", 
            "Nearest Shrunken Centroid", "Neural Network", "Support Vector Machine", 
            "Mixture Discriminant Analysis", "Single Hidden Layer Neural Net", 
            "k-Nearest Neighbor", "SG Boost", "Random Forest"),
    Accuracy = c(log_metrics$Accuracy, lda_metrics$Accuracy, penalized_metrics$Accuracy, 
               nsc_metrics$Accuracy, net_metrics$Accuracy, svm_metrics$Accuracy, 
               mda_metrics$Accuracy, shlnn_metrics$Accuracy, knn_metrics$Accuracy, 
               sgboost_metrics$Accuracy, rf_metrics$Accuracy))

# Sort the summary table by Accuracy in descending order
accuracy_summary <- accuracy_summary |>
    arrange(desc(Accuracy))

# Print the sorted accuracy summary table
print(accuracy_summary)
```
